import os
import time
import warnings
from dotenv import load_dotenv

# LangChain deprecation warnings ë¬´ì‹œ
warnings.filterwarnings("ignore", category=DeprecationWarning)

import streamlit as st
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_chroma import Chroma
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

load_dotenv()

# â–¶ï¸ API í‚¤ í™•ì¸
api_key = os.getenv("UPSTAGE_API_KEY")
if not api_key:
    st.error("â—ï¸Upstage API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# â–¶ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”©
embedding = UpstageEmbeddings(
    model="solar-embedding-1-large",
    upstage_api_key=api_key
)

vectorstore = Chroma(
    persist_directory="../storage/chroma_db",
    embedding_function=embedding
)
retriever = vectorstore.as_retriever(k=2)

# â–¶ï¸ ì±—ë´‡ ì´ˆê¸°í™”
chat = ChatUpstage(
    model="solar-pro",
    upstage_api_key=api_key
)

# â–¶ï¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
contextualize_q_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ, ë¬¸ë§¥ ì—†ì´ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì„ ë‹¤ì‹œ í‘œí˜„í•˜ì„¸ìš”."),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)
history_aware_retriever = create_history_aware_retriever(chat, retriever, contextualize_q_prompt)

def create_qa_prompt_with_language(language_code: str):
    """ì–¸ì–´ë³„ QA í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    language_instruction = get_language_instruction(language_code)
    
    system_prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ json í˜•ì‹ìœ¼ë¡œ ëœ ë²•ë¥  ë¶„ì„ ìë£Œì…ë‹ˆë‹¤. ì–‘ì‹ì— ë§ê²Œ í•­ëª© ë³„ë¡œ ìœ„ë°˜ ì—¬ë¶€ë¥¼ ë¶„ì„í•˜ê³  ë“±ê¸‰í™”í•´ ì£¼ì„¸ìš”.  
         ìµœì €ì„ê¸ˆ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ ë…„ : ì›
    2023: 9620,
    2024: 9860,
    2025: 10030
ë‹¹ì‹ ì€ ë…¸ë™ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” OCRë¡œ ì¶”ì¶œëœ ê·¼ë¡œê³„ì•½ì„œ í•­ëª©ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ "ì „ì²´ ë¶„ì„ ê²°ê³¼(ì´ì  í¬í•¨)", "í•˜ì´ë¼ì´íŠ¸ í•­ëª©", "ë²•ë¥  í•´ì„" ì„¸ ê°€ì§€ ì„¹ì…˜ì„ ë°˜ë“œì‹œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
JSONì´ë‚˜ ì½”ë“œ íœìŠ¤ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , ë‹¤ìŒì˜ ì˜ˆì‹œ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ì˜ˆì‹œ ì¶œë ¥ í˜•ì‹:
â€”
ì „ì²´ ë¶„ì„ ê²°ê³¼:
ì´ì : [ì—¬ê¸°ì— ê³„ì‚°ëœ ìˆ«ì(ì†Œìˆ˜ì  ê°€ëŠ¥)]  
[ê°„ëµí•œ ìš”ì•½ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”]

í•˜ì´ë¼ì´íŠ¸ í•­ëª©
1. [ì²« ë²ˆì§¸ í•µì‹¬ ìœ„ë°˜ ìš”ì†Œ ë˜ëŠ” ì£¼ì˜ ì‚¬í•­]
2. [ë‘ ë²ˆì§¸ í•µì‹¬ ìœ„ë°˜ ìš”ì†Œ ë˜ëŠ” ì£¼ì˜ ì‚¬í•­]
3. ...

ë²•ë¥  í•´ì„
1. [ì²« ë²ˆì§¸ ìœ„ë°˜ ìš”ì†Œì— ëŒ€í•œ ë²•ì  ê·¼ê±°ì™€ ì„¤ëª…]
2. [ë‘ ë²ˆì§¸ ìœ„ë°˜ ìš”ì†Œì— ëŒ€í•œ ë²•ì  ê·¼ê±°ì™€ ì„¤ëª…]
3. ...

ì „ì²´ ì‹¬ì¸µ ë¶„ì„:
[ì—¬ê¸°ì— ìµœì†Œ 5~6ë¬¸ì¥ ì´ìƒì˜ ê¸¸ê³  ìƒì„¸í•œ ë¶„ì„ì„ ì‘ì„±í•˜ì„¸ìš”. 
ì˜ˆ: ê³„ì•½ì„œì˜ ì–´ë–¤ ì¡°í•­ì´ ë…¸ë™ë²•ìƒ ì™œ ë¬¸ì œê°€ ë˜ëŠ”ì§€, ì™¸êµ­ì¸ ê·¼ë¡œì ê´€ì ì—ì„œ ì¶”ê°€ ë¦¬ìŠ¤í¬ëŠ” ë¬´ì—‡ì¸ì§€, í–¥í›„ ê°œì„  ë°©ì•ˆê³¼ ì˜ˆë°©ë²• ë“±ì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ ]
â€”

ì¶”ê°€ë¡œ ë°˜ë“œì‹œ ê³ ë ¤í•´ì•¼ í•  ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1. %%ë…„ ê¸°ì¤€ í•œêµ­ì˜ ìµœì €ì„ê¸ˆì€ ì‹œê°„ë‹¹ %%ì›ì…ë‹ˆë‹¤.
2. ìµœì €ì„ê¸ˆ ë¯¸ë‹¬ ì‹œ ê·¼ë¡œê¸°ì¤€ë²• ì œ6ì¡° ë° ì œ55ì¡° ìœ„ë°˜ì…ë‹ˆë‹¤.
3. ì£¼ 40ì‹œê°„ ê·¼ë¬´ ì‹œ ì›” 209ì‹œê°„ìœ¼ë¡œ ê°„ì£¼í•˜ë©°, ì›”ê¸‰ì´ ëª…ì‹œëœ ê²½ìš° ì‹œê¸‰ = ì›”ê¸‰ Ã· 209ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
4. ì¤‘ì‹ë³´ì¡°ë¹„, ìœ ë¥˜ë¹„ ë“±ì€ ìµœì €ì„ê¸ˆ ê³„ì‚°ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.
5. ìˆ˜ìŠµê¸°ê°„ ê°ì•¡ì€ ì°¨ë³„ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìœ¼ë©°, ëª…í™•íˆ ëª…ì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
6. ì™¸êµ­ì¸ ê·¼ë¡œìì˜ ê²½ìš° ìˆ™ì†Œ ì œê³µ, í†µì—­, ì²´ë¥˜ìê²© ì •ë³´ ë“±ë„ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

ê° ìœ„ë°˜ í•­ëª©ë³„ ê°€ì¤‘ì¹˜ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
- ìµœì €ì„ê¸ˆ ë¯¸ë‹¬: 3ì 
- ìˆ˜ìŠµê¸°ê°„ ì¤‘ ê°ì•¡: 2ì 
- íœ´ì¼ ë¯¸ê¸°ì¬: 2ì 
- ìˆ™ì†Œì œê³µ ë¯¸ê¸°ì¬(ì™¸êµ­ì¸): 2ì 
- 4ëŒ€ë³´í—˜ ë¯¸ê°€ì…: 1.5ì 
- ì„ê¸ˆì§€ê¸‰ì¼/ì§€ê¸‰ë°©ì‹ ë¶ˆëª…í™•: 1ì 
- ê¸°íƒ€ ì¡°í•­ ëˆ„ë½: 0.5ì 

{language_instruction}

ğŸ“ ì¶œì²˜ ë¬¸ì„œ: {{context}}"""
    
    return ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ])

# RAG ì²´ì¸ì€ ì‚¬ìš©ì ì…ë ¥ ì‹œ ë™ì ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤

# â–¶ï¸ Streamlit UI
st.title("ğŸ“š LawRo ë²•ë¥  ìƒë‹´ Chatbot")

# â–¶ï¸ ì–¸ì–´ ì„ íƒ ì˜µì…˜ ì¶”ê°€
language_options = {
    "í•œêµ­ì–´": "korean",
    "English": "english", 
    "ä¸­æ–‡": "chinese",
    "Tiáº¿ng Viá»‡t": "vietnamese",
    "æ—¥æœ¬èª": "japanese",
    "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢": "thai",
    "Bahasa Indonesia": "indonesian",
    "Filipino": "tagalog",
    "EspaÃ±ol": "spanish",
    "FranÃ§ais": "french"
}

selected_language_display = st.selectbox(
    "ğŸŒ ë‹µë³€ ì–¸ì–´ ì„ íƒ",
    options=list(language_options.keys()),
    index=0
)
selected_language = language_options[selected_language_display]

# ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­
def get_language_instruction(language_code: str) -> str:
    """ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    language_prompts = {
        "korean": "ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.",
        "english": "Please respond in English only.",
        "chinese": "è¯·åªç”¨ä¸­æ–‡å›ç­”ã€‚",
        "vietnamese": "Vui lÃ²ng chá»‰ tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.",
        "japanese": "æ—¥æœ¬èªã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚",
        "thai": "à¸à¸£à¸¸à¸“à¸²à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™",
        "indonesian": "Silakan jawab hanya dalam bahasa Indonesia.",
        "tagalog": "Mangyaring sumagot sa wikang Filipino lamang.",
        "spanish": "Por favor responde solo en espaÃ±ol.",
        "french": "Veuillez rÃ©pondre uniquement en franÃ§ais."
    }
    return language_prompts.get(language_code, "ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.")

# â–¶ï¸ ëŒ€í™” ìƒíƒœ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = []

# â–¶ï¸ ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# â–¶ï¸ ì…ë ¥ ì²˜ë¦¬
MAX_MESSAGES = 6

if prompt := st.chat_input("ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # â–¶ï¸ ìµœê·¼ Nê°œë§Œ ìœ ì§€
    if len(st.session_state.messages) > MAX_MESSAGES:
        st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        # ì„ íƒëœ ì–¸ì–´ë¡œ QA í”„ë¡¬í”„íŠ¸ ìƒì„±
        qa_prompt = create_qa_prompt_with_language(selected_language)
        question_answer_chain = create_stuff_documents_chain(chat, qa_prompt)
        rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
        
        result = rag_chain.invoke({
            "input": prompt,
            "chat_history": st.session_state.messages
        })

        # â–¶ï¸ ì¦ê±°ìë£Œ ë‚´ìš© ì¶œë ¥
        docs = result.get("context", [])
        with st.expander("ğŸ“‚ ê´€ë ¨ ë¬¸ì„œ"):
            if isinstance(docs, list):
                for i, doc in enumerate(docs, 1):
                    content = getattr(doc, "page_content", "ì¶œì²˜ ì—†ìŒ")
                    st.markdown(f"**[{i}]** {content.strip()[:500]}...")  # ìµœëŒ€ 500ì

        # â–¶ï¸ ë‹µë³€ ì• ë‹ˆë©”ì´ì…˜ ì¶œë ¥
        for chunk in result["answer"].split(" "):
            full_response += chunk + " "
            message_placeholder.markdown(full_response + "â–Œ")
            time.sleep(0.02)
        message_placeholder.markdown(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})
