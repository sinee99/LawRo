import os
import cv2
import json
import requests
import matplotlib.pyplot as plt
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage
from langchain_core.messages import HumanMessage
from llm_utils import (
    build_prompt,
    call_llm_and_parse,
    get_llm_judgment
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib as mpl
mpl.rcParams['font.family'] = 'AppleGothic'
mpl.rcParams['axes.unicode_minus'] = False

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv("API_KEY")
OCR_URL = "https://ap-northeast-2.apistage.ai/v1/document-ai/ocr"
HEADERS = {"Authorization": f"Bearer {API_KEY}"}


def review_and_edit(fields: dict) -> dict:
    """
    ì¶”ì¶œëœ JSON í•­ëª©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê³  ì˜ëª»ëœ ê°’ì„
    ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”í˜• ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
    ì—”í„°ë§Œ ëˆ„ë¥´ë©´ ê¸°ì¡´ ê°’ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    print("\nğŸ“‹ ì¶”ì¶œëœ í•­ëª©ì„ ê²€í† í•˜ê³  ì˜ëª»ëœ ê°’ì€ ìˆ˜ì •í•˜ì„¸ìš”. ì—”í„°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€:")
    def _recursive_edit(d, parent_key="") -> dict:
        for k, v in d.items():
            if isinstance(v, dict):
                print(f"\n-- {k} (í•˜ìœ„ í•­ëª©) --")
                d[k] = _recursive_edit(v, k)
            else:
                prompt = f"{parent_key + '.' if parent_key else ''}{k} [{v}]: "
                user_input = input(prompt).strip()
                if user_input:
                    d[k] = user_input
        return d

    return _recursive_edit(fields)


def main():
    # ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥
    image_path = input("ğŸ“ ë¶„ì„í•  ê·¼ë¡œê³„ì•½ì„œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not os.path.exists(image_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}")
        return

    # ì´ë¯¸ì§€ ì½ê¸°
    image = cv2.imread(image_path)

    # OCR ìš”ì²­
    with open(image_path, "rb") as img_file:
        files = {"image": img_file}
        resp = requests.post(OCR_URL, headers=HEADERS, files=files)
    if resp.status_code != 200:
        print(f"âŒ OCR ì‹¤íŒ¨: {resp.status_code}\n{resp.text}")
        return

    # OCR ê²°ê³¼ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    ocr_data = resp.json()
    full_text = " ".join(p.get("text", "") for p in ocr_data.get("pages", []))
    print("\nğŸ“„ OCR ê²°ê³¼ ì¼ë¶€:")
    print((full_text[:500] + '...') if len(full_text) > 500 else full_text)

    # LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ë° í•µì‹¬ ì •ë³´ ì¶”ì¶œ
    prompt = build_prompt(full_text)
    extracted_fields = call_llm_and_parse(prompt, API_KEY)

    # ì‚¬ìš©ì ê²€í†  ë° ìˆ˜ì •
    extracted_fields = review_and_edit(extracted_fields)

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“ ìµœì¢… í™•ì¸ëœ ê²°ê³¼:")
    print(json.dumps(extracted_fields, indent=2, ensure_ascii=False))

    # ë²•ë¥  ìœ„ë°˜ íŒë‹¨ ì¶”ê°€ í˜¸ì¶œ
    print("\n ë²•ë¥  ìœ„ë°˜ íŒë‹¨ ì¤‘â€¦")
    judgment = get_llm_judgment(full_text, API_KEY)
    print("âš–ï¸ ë²•ë¥  ìœ„ë°˜ íŒë‹¨ ê²°ê³¼:\n", judgment)

    # OCR ë°•ìŠ¤ ê°•ì¡° ì´ë¯¸ì§€ ë§Œë“¤ê¸°
    highlighted = image.copy()
    for page in ocr_data.get("pages", []):
        for word in page.get("words", []):
            v = word["boundingBox"]["vertices"]
            cv2.rectangle(highlighted, (v[0]["x"], v[0]["y"]), (v[2]["x"], v[2]["y"]), (0, 0, 255), 2)

    # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    axs[0].set_title("ì›ë³¸ ì´ë¯¸ì§€")
    axs[0].axis("off")

    axs[1].imshow(cv2.cvtColor(highlighted, cv2.COLOR_BGR2RGB))
    axs[1].set_title("OCR ê°•ì¡° ì´ë¯¸ì§€")
    axs[1].axis("off")

    plt.tight_layout()
    plt.savefig("ocr_highlighted.png", dpi=150)
    print("âœ ê°•ì¡° ì´ë¯¸ì§€ê°€ ocr_highlighted.pngì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
