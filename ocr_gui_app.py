import streamlit as st
import requests
import cv2
import numpy as np
import json
from PIL import Image
from rapidfuzz import fuzz
import re

# --- ì„¤ì • ---
API_KEY = "up_KvE6eQR9HV5o3NAUoRNCITGI9s63v"
API_URL = "https://ap-northeast-2.apistage.ai/v1/document-ai/ocr"
HEADERS = {"Authorization": f"Bearer {API_KEY}"}

# --- í•„ìˆ˜ í‚¤ì›Œë“œ ---
required_fields = {
    "ì‚¬ìš©ì ì •ë³´": ["ì„±ëª…", "ì—…ì²´ëª…", "ì†Œì¬ì§€", "ì „í™”ë²ˆí˜¸", "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸", "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸"],
    "ê·¼ë¡œì ì •ë³´": ["ê·¼ë¡œì", "ì„±ëª…", "ìƒë…„ì›”ì¼", "ë³¸êµ­ì£¼ì†Œ"],
    "ê·¼ë¡œê³„ì•½ê¸°ê°„": ["ê·¼ë¡œê³„ì•½ê¸°ê°„", "ìˆ˜ìŠµê¸°ê°„", "ì‹ ê·œ", "ì¬ì…êµ­"],
    "ê·¼ë¡œì¥ì†Œ": ["ê·¼ë¡œì¥ì†Œ", "ì¥ì†Œ"],
    "ì—…ë¬´ë‚´ìš©": ["ì—…ì¢…", "ì‚¬ì—…ë‚´ìš©", "ì§ë¬´ë‚´ìš©"],
    "ê·¼ë¡œì‹œê°„": ["ê·¼ë¡œì‹œê°„", "ì‹œ", "ë¶„", "êµëŒ€ì œ"],
    "íœ´ê²Œì‹œê°„": ["íœ´ê²Œì‹œê°„", "ë¶„"],
    "íœ´ì¼": ["íœ´ì¼", "ì¼ìš”ì¼", "í† ìš”ì¼", "ê³µíœ´ì¼", "ìœ ê¸‰", "ë¬´ê¸‰"],
    "ì„ê¸ˆ": ["í†µìƒì„ê¸ˆ", "ê¸°ë³¸ê¸‰", "ìˆ˜ë‹¹", "ìƒì—¬ê¸ˆ", "ìˆ˜ìŠµ", "ê°€ì‚°ìˆ˜ë‹¹"],
    "ì„ê¸ˆì§€ê¸‰ì¼": ["ë§¤ì›”", "ë§¤ì£¼", "ì§€ê¸‰ì¼", "ìš”ì¼", "ê³µíœ´ì¼", "ì „ì¼"],
    "ì§€ê¸‰ë°©ë²•": ["ê³„ì¢Œì§€ê¸‰", "í˜„ê¸ˆì§€ê¸‰", "í†µì¥", "ë„ì¥", "ì§ì ‘ì§€ê¸‰"],
    "ìˆ™ì‹ì œê³µ": ["ìˆ™ì†Œ", "ì œê³µ", "ë¯¸ì œê³µ", "ìë¹„", "ì‹ì‚¬", "ìˆ™ì†Œì œê³µ", "ì‹ì‚¬ì œê³µ", "ì¡°ì‹", "ì¤‘ì‹", "ì„ì‹"],
    "ê·œì •ì¤€ìˆ˜": ["ì·¨ì—…ê·œì¹™", "ë‹¨ì²´í˜‘ì•½", "ì„±ì‹¤", "ì´í–‰"],
    "ê¸°íƒ€ì¡°í•­": ["í˜‘ì˜", "ê¸°íƒ€ì‚¬í•­", "ì¶”ê°€", "ììœ í˜‘ì˜"]
}

# --- ë²• ìœ„ë°˜ ë£° ---
law_violation_rules = {
    "ìˆ˜ìŠµê¸°ê°„ 6ê°œì›” ì´ˆê³¼": r"ìˆ˜ìŠµ.*(6ê°œì›”|180ì¼|ì´ìƒ)",
    "ì£¼ 52ì‹œê°„ ì´ˆê³¼ ê·¼ë¡œ": r"(52ì‹œê°„|í•˜ë£¨\s?10ì‹œê°„\s?ì´ˆê³¼|ì—°ì¥ê·¼ë¡œ.*ë¬´ì œí•œ)",
    "íœ´ì¼ ë¬´ê¸‰ ì²˜ë¦¬": r"ë¬´ê¸‰.*(íœ´ì¼|ê³µíœ´ì¼)",
    "ì„ê¸ˆ ë¯¸ì§€ê¸‰ ì–¸ê¸‰": r"(ì„ê¸ˆ.*ì§€ê¸‰í•˜ì§€.*ì•ŠëŠ”ë‹¤|ë¬´ê¸‰ê·¼ë¡œ|ì§€ì—°ì§€ê¸‰)"
}

def is_similar(word, keyword, threshold=85):
    return fuzz.ratio(word, keyword) >= threshold

def analyze_text(text):
    found_fields = {}
    lowered_text = text.lower()
    words = lowered_text.split()

    for category, keywords in required_fields.items():
        found = []
        for keyword in keywords:
            keyword_lower = keyword.lower()
            # 1. ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ ìš°ì„  ê²€ì‚¬
            if keyword_lower in lowered_text:
                found.append(keyword)
            else:
                # 2. ìœ ì‚¬ë„ íŒë‹¨
                for word in words:
                    if is_similar(word, keyword_lower):
                        found.append(keyword)
                        break
        if found:
            found_fields[category] = found

    missing_fields = {}
    for category, keywords in required_fields.items():
        found = found_fields.get(category, [])
        missing = list(set(keywords) - set(found))
        if missing:
            missing_fields[category] = missing

    violations = []
    for label, pattern in law_violation_rules.items():
        if re.search(pattern, lowered_text):
            violations.append(label)

    return found_fields, missing_fields, violations

def highlight_boxes(image, ocr_data):
    for page in ocr_data.get("pages", []):
        for word in page.get("words", []):
            vertices = word["boundingBox"]["vertices"]
            pt1 = (vertices[0]["x"], vertices[0]["y"])
            pt2 = (vertices[2]["x"], vertices[2]["y"])
            cv2.rectangle(image, pt1, pt2, (0, 0, 255), 2)
    return image

# --- Streamlit UI ---
st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ OCR & ë¶„ì„")

uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.png, .jpg, .jpeg)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    np_image = np.array(image)
    st.image(image, caption="ì›ë³¸ ì´ë¯¸ì§€", use_column_width=True)

    with st.spinner("ğŸ§  OCR ë¶„ì„ ì¤‘..."):
        files = {"image": (uploaded_file.name, uploaded_file.getvalue())}
        response = requests.post(API_URL, headers=HEADERS, files=files)

        if response.status_code == 200:
            ocr_result = response.json()
            full_text = " ".join([p.get("text", "") for p in ocr_result.get("pages", [])])
            analyzed_image = highlight_boxes(np_image.copy(), ocr_result)

            st.image(analyzed_image, caption="í…ìŠ¤íŠ¸ ê°•ì¡° ì´ë¯¸ì§€", use_column_width=True)

            st.subheader("ğŸ“„ OCR ì „ì²´ í…ìŠ¤íŠ¸")
            st.text(full_text)

            found, missing, violations = analyze_text(full_text)

            st.subheader("âœ… í¬í•¨ëœ í•„ìˆ˜ í•­ëª©")
            st.json(found)

            if missing:
                st.subheader("âš ï¸ ëˆ„ë½ëœ í•„ìˆ˜ í•­ëª©")
                st.json(missing)
            else:
                st.success("ëª¨ë“  í•„ìˆ˜ í•­ëª©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

            if violations:
                st.subheader("âŒ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ ê°€ëŠ¥ ì¡°í•­")
                st.json(violations)
            else:
                st.success("ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ ì¡°í•­ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            st.error(f"OCR ì‹¤íŒ¨: {response.status_code}")
            st.text(response.text)
