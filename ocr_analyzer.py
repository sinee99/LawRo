import streamlit as st
import requests
import json
import re
from rapidfuzz import fuzz

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ” Upstage OCR API ì„¤ì •
API_KEY = "up_KvE6eQR9HV5o3NAUoRNCITGI9s63v"  # â† ì—¬ê¸°ì— ë³¸ì¸ í‚¤ ì…ë ¥ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì²˜ë¦¬
OCR_URL = "https://ap-northeast-2.apistage.ai/v1/document-ai/ocr"
OCR_HEADERS = {"Authorization": f"Bearer {API_KEY}"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_ocr_text(raw_text):
    lines = raw_text.splitlines()
    cleaned = []

    for line in lines:
        line = re.sub(r"[â– â—â˜‘ï¸âœ”ï¸]", "[X]", line)
        line = re.sub(r"[â–¡â¬œï¸â˜]", "[ ]", line)
        line = line.strip()

        if not line or re.match(r"^[-=]{3,}$", line):
            continue
        cleaned.append(line)

    return "\n".join(cleaned)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ ì‚¬ë„ ë¹„êµ
def is_similar(word, keyword, threshold=85):
    return fuzz.ratio(word.lower(), keyword.lower()) >= threshold or keyword.lower() in word.lower()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í‚¤ì›Œë“œ ì •ì˜
required_fields = {
    "ì‚¬ìš©ì ì •ë³´": ["ì„±ëª…", "ì—…ì²´ëª…", "ì†Œì¬ì§€", "ì „í™”ë²ˆí˜¸", "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸", "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸"],
    "ê·¼ë¡œì ì •ë³´": ["ê·¼ë¡œì", "ì„±ëª…", "ìƒë…„ì›”ì¼", "ë³¸êµ­ì£¼ì†Œ"],
    "ê·¼ë¡œê³„ì•½ê¸°ê°„": ["ê·¼ë¡œê³„ì•½ê¸°ê°„", "ìˆ˜ìŠµê¸°ê°„", "ì‹ ê·œ", "ì¬ì…êµ­"],
    "ê·¼ë¡œì¥ì†Œ": ["ê·¼ë¡œì¥ì†Œ", "ì¥ì†Œ"],
    "ì—…ë¬´ë‚´ìš©": ["ì—…ì¢…", "ì‚¬ì—…ë‚´ìš©", "ì§ë¬´ë‚´ìš©"],
    "ê·¼ë¡œì‹œê°„": ["ê·¼ë¡œì‹œê°„", "ì‹œ", "ë¶„", "êµëŒ€ì œ"],
    "íœ´ê²Œì‹œê°„": ["íœ´ê²Œì‹œê°„", "ë¶„"],
    "íœ´ì¼": ["íœ´ì¼", "ì¼ìš”ì¼", "í† ìš”ì¼", "ê³µíœ´ì¼", "ìœ ê¸‰", "ë¬´ê¸‰"]
}

law_violation_rules = {
    "ìˆ˜ìŠµê¸°ê°„ 6ê°œì›” ì´ìƒ": lambda text: re.search(r"ìˆ˜ìŠµ.*(6ê°œì›”|180ì¼|ì´ìƒ)", text),
    "ì£¼ 52ì‹œê°„ ì´ˆê³¼ ê·¼ë¬´": lambda text: re.search(r"(52ì‹œê°„|í•˜ë£¨\s?10ì‹œê°„\s?ì´ˆê³¼|ì—°ì¥ê·¼ë¡œ.*ë¬´ì œí•œ)", text),
    "ë¬´ê¸‰ íœ´ì¼": lambda text: "ë¬´ê¸‰" in text and "íœ´ì¼" in text,
    "ì„ê¸ˆ ë¯¸ì§€ê¸‰ ê°€ëŠ¥ì„±": lambda text: re.search(r"(ì„ê¸ˆ.*ì§€ê¸‰í•˜ì§€.*ì•ŠëŠ”ë‹¤|ë¬´ê¸‰ê·¼ë¡œ|ì§€ì—°ì§€ê¸‰)", text)
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¶„ì„ í•¨ìˆ˜
def analyze_contract_text(text):
    extracted_keywords = {}
    words = text.split()

    for category, keywords in required_fields.items():
        found = []
        for keyword in keywords:
            for word in words:
                if is_similar(word, keyword):
                    found.append(keyword)
                    break
        if found:
            extracted_keywords[category] = found

    missing_fields = {}
    for category, keywords in required_fields.items():
        found = extracted_keywords.get(category, [])
        missing = list(set(keywords) - set(found))
        if missing:
            missing_fields[category] = missing

    violations = []
    for label, rule in law_violation_rules.items():
        if rule(text):
            violations.append(label)

    return extracted_keywords, missing_fields, violations

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OCR í•¨ìˆ˜
def call_ocr_api(file):
    files = {"image": (file.name, file.getvalue())}
    response = requests.post(OCR_URL, headers=OCR_HEADERS, files=files)
    if response.status_code == 200:
        result = response.json()
        text = " ".join([p.get("text", "") for p in result.get("pages", [])])
        return preprocess_ocr_text(text)
    else:
        raise ValueError(f"OCR ì‹¤íŒ¨: {response.status_code}\n{response.text}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UI
st.set_page_config(page_title="ê·¼ë¡œê³„ì•½ì„œ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“„ ê·¼ë¡œê³„ì•½ì„œ ìë™ ë¶„ì„ê¸° (ì´ë¯¸ì§€ ì—…ë¡œë“œ + OCR + ë²• ìœ„ë°˜ ê°ì§€)")

uploaded_file = st.file_uploader("ğŸ“¤ ê·¼ë¡œê³„ì•½ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.png, .jpg, .jpeg)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ê³„ì•½ì„œ ì´ë¯¸ì§€", use_column_width=True)
    with st.spinner("ğŸ” OCR ë¶„ì„ ë° ì „ì²˜ë¦¬ ì¤‘..."):
        try:
            clean_text = call_ocr_api(uploaded_file)

            st.subheader("ğŸ§¾ ì „ì²˜ë¦¬ëœ ê³„ì•½ì„œ í…ìŠ¤íŠ¸ (ìš”ì•½)")
            st.text(clean_text[:1000] + "..." if len(clean_text) > 1000 else clean_text)

            found, missing, violations = analyze_contract_text(clean_text)

            st.subheader("âœ… í¬í•¨ëœ í•„ìˆ˜ í•­ëª©")
            st.json(found)

            st.subheader("âš ï¸ ëˆ„ë½ëœ í•„ìˆ˜ í•­ëª©")
            if missing:
                st.json(missing)
            else:
                st.success("ëª¨ë“  í•­ëª©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

            st.subheader("âŒ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ ê°€ëŠ¥ ì¡°í•­")
            if violations:
                for v in violations:
                    st.error(f"ğŸš¨ {v}")
            else:
                st.success("ê°ì§€ëœ ìœ„ë°˜ ì¡°í•­ ì—†ìŒ")

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
