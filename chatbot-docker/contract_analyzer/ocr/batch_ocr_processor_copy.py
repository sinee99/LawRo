import os
from ocr.upstage_ocr import extract_text_from_image
from utils.s3_utils import download_s3_files
from config.settings import TMP_DIR
import json

OCR_CACHE_DIR = os.path.join(TMP_DIR, "ocr_results")
os.makedirs(OCR_CACHE_DIR, exist_ok=True)

def ocr_pages_from_s3(bucket: str, s3_keys: list[str], user_id: str, contract_id: str) -> list[dict]:
    """
    S3ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í›„ í˜ì´ì§€ë³„ OCR ìˆ˜í–‰í•˜ì—¬
    ê° í˜ì´ì§€ OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    cache_file = os.path.join(OCR_CACHE_DIR, f"{user_id}_{contract_id}.json")

    # 1. ìºì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ì–´ì„œ ë°˜í™˜
    if os.path.exists(cache_file):
        print(f"ğŸ” OCR ìºì‹œ íŒŒì¼ ë°œê²¬: {cache_file} - íŒŒì¼ ë¡œë“œ")
        with open(cache_file, "r", encoding="utf-8") as f:
            return json.load(f)
        
    local_image_dir = os.path.join(TMP_DIR, "images")
    os.makedirs(local_image_dir, exist_ok=True)

    local_image_paths = download_s3_files(bucket, s3_keys, local_image_dir)

    page_results = []
    for idx, path in enumerate(local_image_paths):
        print(f"[{idx+1}/{len(local_image_paths)}] OCR ì²˜ë¦¬ ì¤‘: {path}")
        result = extract_text_from_image(path)
        print("OCR API ì‘ë‹µ:", result)  # ì‘ë‹µ ì›ë³¸ í™•ì¸ìš©
        
        page_results.append({
            "page": idx + 1,
            "html": result["content"]["html"],
            "raw_result": result
        })
        
    # 3. OCR ê²°ê³¼ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(page_results, f, ensure_ascii=False, indent=2)
    print(f"âœ… OCR ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_file}")


    return page_results
