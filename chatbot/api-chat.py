# solar-llm-master/chatbot.py

import os
from dotenv import load_dotenv

from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_community.vectorstores import Chroma
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

load_dotenv()

# â–¶ï¸ ì„ë² ë”© & ë²¡í„° DB
embedding = UpstageEmbeddings(
    model="solar-embedding-1-large",
    upstage_api_key=os.getenv("UPSTAGE_API_KEY")
)
vectorstore = Chroma(
    persist_directory="chroma_db",
    embedding_function=embedding
)
retriever = vectorstore.as_retriever(k=2)

# â–¶ï¸ Upstage ì±— ëª¨ë¸
chat = ChatUpstage(
    model="solar-pro",
    upstage_api_key=os.getenv("UPSTAGE_API_KEY")
)

# â–¶ï¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
contextualize_q_prompt = ChatPromptTemplate.from_messages([
    ("system", "ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ, ë¬¸ë§¥ ì—†ì´ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì„ ë‹¤ì‹œ í‘œí˜„í•˜ì„¸ìš”."),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])
qa_prompt = ChatPromptTemplate.from_messages([
    ("system", 
     """ì§ˆë¬¸ì— ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë‹µì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”. ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. ë²•ë¥ ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”. ê´€ë ¨ë˜ì§€ ì•Šì„ê²½ìš° ë²•ë¥ ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” ë§ì„ í•´ì£¼ì„¸ìš”.

ğŸ“ë‹µë³€ ë‚´ìš©:  
ğŸ“ì¶œì²˜ ë¬¸ì„œ: {context}"""),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

# â–¶ï¸ RAG ì²´ì¸ ìƒì„±
history_aware_retriever = create_history_aware_retriever(chat, retriever, contextualize_q_prompt)
question_answer_chain = create_stuff_documents_chain(chat, qa_prompt)
rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

# â–¶ï¸ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def ask_chatbot(question: str, history: list):
    result = rag_chain.invoke({
        "input": question,
        "chat_history": history
    })

    docs = result.get("context", [])
    sources = [getattr(doc, "page_content", "")[:300] for doc in docs]

    return {
        "answer": result.get("answer", ""),
        "evidence": sources
    }
